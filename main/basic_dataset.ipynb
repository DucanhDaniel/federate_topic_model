{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cf747fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import file_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dcc9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "from scipy.sparse import issparse\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from data.preprocess import Preprocess\n",
    "from typing import List, Tuple, Union, Mapping, Any, Callable, Iterable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0becdb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocEmbedModel:\n",
    "    def __init__(self, \n",
    "                 model : Union[str, callable] = \"all-MiniLM-L6-v2\",\n",
    "                 device : str = \"cuda\",\n",
    "                 verbose = False):\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if isinstance(model, str):\n",
    "            self.model = SentenceTransformer(model, device = device)\n",
    "        else:\n",
    "            self.model = model\n",
    "        \n",
    "    def encode(self, \n",
    "                docs: List[str],\n",
    "                convert_to_tensors: bool = False):\n",
    "        embeddings = self.model.encode(\n",
    "                        docs, \n",
    "                        convert_to_tensor=convert_to_tensors,\n",
    "                        show_progress_bar=self.verbose\n",
    "                    )\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d8fcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "doc_embed_test = DocEmbedModel()\n",
    "output = doc_embed_test.encode(\n",
    "    [\"hello hi i am a man\", \"good morning\"],\n",
    "    convert_to_tensors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58074376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 384])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bca7ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawDataset:\n",
    "    def __init__(self,\n",
    "                 docs, \n",
    "                 preprocess = None,\n",
    "                 batch_size = 200,\n",
    "                 device = \"cuda\",\n",
    "                 as_tensor = True,\n",
    "                 contextual_embed = False,\n",
    "                 pretrained_WE = False,\n",
    "                 doc_embed_model = \"all-MiniLM-L6-v2\",\n",
    "                 embed_model_device = None,\n",
    "                 vocab = None,\n",
    "                 verbose = False):\n",
    "        if preprocess is None:\n",
    "            preprocess = Preprocess(verbose=verbose)\n",
    "\n",
    "        rst = preprocess.preprocess(docs, pretrained_WE=pretrained_WE)\n",
    "\n",
    "        self.train_data = rst[\"train_bow\"]\n",
    "        self.train_texts = rst[\"train_texts\"]\n",
    "        self.vocab = rst[\"vocab\"]\n",
    "\n",
    "        if issparse(self.train_data):\n",
    "            self.train_data = self.train_data.toarray()\n",
    "\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "        if contextual_embed:\n",
    "            if embed_model_device is None:\n",
    "                embed_model_device = device\n",
    "            \n",
    "            if isinstance(doc_embed_model, str):\n",
    "                self.doc_embedder = DocEmbedModel(doc_embed_model, device = embed_model_device)\n",
    "            else:\n",
    "                self.doc_embedder = doc_embed_model\n",
    "            \n",
    "            self.train_contextual_embed = self.doc_embedder.encode(docs)\n",
    "            self.contextual_embed_size = self.train_contextual_embed.shape[1]\n",
    "\n",
    "        if as_tensor:\n",
    "            if contextual_embed:\n",
    "                self.train_data = np.concatenate((self.train_data, self.train_contextual_embed), axis = 1)\n",
    "            \n",
    "            self.train_data = torch.from_numpy(self.train_data).float().to(device)\n",
    "\n",
    "            self.train_dataloader = DataLoader(self.train_data, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae47e574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading train texts: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "parsing texts: 100%|██████████| 2/2 [00:00<00:00, 1967.31it/s]\n",
      "2025-07-12 22:29:45,148 - TopMost - Real vocab size: 8\n",
      "2025-07-12 22:29:45,149 - TopMost - Real training size: 2 \t avg length: 4.000\n"
     ]
    }
   ],
   "source": [
    "### test\n",
    "test_raw_dataset = RawDataset(\n",
    "    docs = [\"hello hi i am a man physics close windown, ahi\", \"good morning\"],\n",
    "    verbose=True,\n",
    "    as_tensor=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c5be68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello man physics close windown ahi', 'good morning']\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(test_raw_dataset.train_texts)\n",
    "print(test_raw_dataset.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db1de14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDataset:\n",
    "    def __init__(self,\n",
    "                 dataset_dir,\n",
    "                 batch_size=200,\n",
    "                 read_labels=False,\n",
    "                 as_tensor=True,\n",
    "                 contextual_embed=False,\n",
    "                 doc_embed_model=\"all-MiniLM-L6-v2\",\n",
    "                 device='cpu'\n",
    "                ):\n",
    "        # train_bow: NxV\n",
    "        # test_bow: Nxv\n",
    "        # word_emeddings: VxD\n",
    "        # vocab: V, ordered by word id.\n",
    "\n",
    "        self.load_data(dataset_dir, read_labels)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "\n",
    "        print(\"train_size: \", self.train_bow.shape[0])\n",
    "        print(\"test_size: \", self.test_bow.shape[0])\n",
    "        print(\"vocab_size: \", self.vocab_size)\n",
    "        print(\"average length: {:.3f}\".format(self.train_bow.sum(1).sum() / self.train_bow.shape[0]))\n",
    "\n",
    "        if contextual_embed:\n",
    "            self.doc_embedder = DocEmbedModel(doc_embed_model, device)\n",
    "            self.train_contextual_embed = self.doc_embedder.encode(self.train_texts)\n",
    "            self.test_contextual_embed = self.doc_embedder.encode(self.test_texts)\n",
    "\n",
    "            self.contextual_embed_size = self.train_contextual_embed.shape[1]\n",
    "\n",
    "        if as_tensor:\n",
    "            if not contextual_embed:\n",
    "                self.train_data = self.train_bow\n",
    "                self.test_data = self.test_bow\n",
    "            else:\n",
    "                self.train_data = np.concatenate((self.train_bow, self.train_contextual_embed), axis=1)\n",
    "                self.test_data = np.concatenate((self.test_bow, self.test_contextual_embed), axis=1)\n",
    "\n",
    "            self.train_data = torch.from_numpy(self.train_data).to(device)\n",
    "            self.test_data = torch.from_numpy(self.test_data).to(device)\n",
    "\n",
    "            self.train_dataloader = DataLoader(self.train_data, batch_size=batch_size, shuffle=True)\n",
    "            self.test_dataloader = DataLoader(self.test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    def load_data(self, path, read_labels):\n",
    "\n",
    "        self.train_bow = scipy.sparse.load_npz(f'{path}/train_bow.npz').toarray().astype('float32')\n",
    "        self.test_bow = scipy.sparse.load_npz(f'{path}/test_bow.npz').toarray().astype('float32')\n",
    "        self.pretrained_WE = scipy.sparse.load_npz(f'{path}/word_embeddings.npz').toarray().astype('float32')\n",
    "\n",
    "        self.train_texts = file_utils.read_text(f'{path}/train_texts.txt')\n",
    "        self.test_texts = file_utils.read_text(f'{path}/test_texts.txt')\n",
    "\n",
    "        if read_labels:\n",
    "            self.train_labels = np.loadtxt(f'{path}/train_labels.txt', dtype=int)\n",
    "            self.test_labels = np.loadtxt(f'{path}/test_labels.txt', dtype=int)\n",
    "\n",
    "        self.vocab = file_utils.read_text(f'{path}/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba87f3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\MachineLearning\\federated_vae\\main\n",
      "['basic_dataset.ipynb', 'basic_trainer.ipynb', 'data', 'evaluation', 'experiment.ipynb', 'model', 'sample.ipynb', 'test_flwr', 'trainer', 'utils', '__init__.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # Xem working directory\n",
    "print(os.listdir())  # Xem file/folder tại đây"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3100a52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size:  11314\n",
      "test_size:  7532\n",
      "vocab_size:  5000\n",
      "average length: 110.543\n"
     ]
    }
   ],
   "source": [
    "### test\n",
    "test_basic_dataset = BasicDataset(\n",
    "    dataset_dir = \"../data/20NG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3aed2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([200, 5000])\n",
      "torch.Size([114, 5000])\n"
     ]
    }
   ],
   "source": [
    "for train_data in test_basic_dataset.train_dataloader:\n",
    "    print(train_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
