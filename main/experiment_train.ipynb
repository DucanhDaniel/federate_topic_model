{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1964b06",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\TMenv\\lib\\site-packages\\torch\\__init__.py:262\u001b[0m\n\u001b[0;32m    258\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    260\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 262\u001b[0m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\TMenv\\lib\\site-packages\\torch\\__init__.py:238\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    236\u001b[0m is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_load_library_flags:\n\u001b[1;32m--> 238\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mkernel32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadLibraryExW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0x00001100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     last_error \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mget_last_error()\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m last_error \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m126\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Tuple, Union, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import os\n",
    "from flwr.common import ndarrays_to_parameters\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Metrics, Context, FitRes, Parameters, Scalar\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {fl.__version__} / PyTorch {torch.__version__}\")\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c028d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size:  11314\n",
      "test_size:  7532\n",
      "vocab_size:  5000\n",
      "average length: 110.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading train texts: 100%|██████████| 5657/5657 [00:00<00:00, 8589.03it/s]\n",
      "parsing texts: 100%|██████████| 5657/5657 [00:00<00:00, 10600.52it/s]\n",
      "loading train texts: 100%|██████████| 5657/5657 [00:00<00:00, 8589.95it/s]\n",
      "parsing texts: 100%|██████████| 5657/5657 [00:00<00:00, 10606.07it/s]\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 2\n",
    "BATCH_SIZE = 256\n",
    "NUM_ROUNDS = 30\n",
    "\n",
    "from test_flwr import get_all_vocab, split_data\n",
    "vocab = get_all_vocab([\"datasets/20NG\"])\n",
    "datasets = split_data(dir = \"datasets/20NG\", num_split=NUM_CLIENTS, vocab = vocab, batch_size= BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805637fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.ETM import ETM\n",
    "from trainer.basic_trainer import BasicTrainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caebed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa431d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.basic_dataset import RawDataset\n",
    "class FlowerClient(NumPyClient):\n",
    "  def __init__(self, net, dataset : RawDataset, id):\n",
    "    self.net = net\n",
    "    self.dataset = dataset\n",
    "    self.trainer = BasicTrainer(net, dataset, epochs = 1, log_interval=10, device = DEVICE, save_model = True, save_interval=NUM_ROUNDS)\n",
    "    self.id = id\n",
    "    self.save_dir = \"model_parameters/\"\n",
    "    self.round_id = 0\n",
    "    self.total_round = NUM_ROUNDS\n",
    "\n",
    "  # return the current local model parameters\n",
    "  def get_parameters(self, config):\n",
    "    return get_parameters(self.net)\n",
    "\n",
    "  # receive global parameter, train, return updated model to server\n",
    "  def fit(self, parameters, config):\n",
    "    set_parameters(self.net, parameters)\n",
    "    self.trainer.train(model_name = f\"ETM_Client{self.id}\")\n",
    "\n",
    "    return get_parameters(self.net), len(self.dataset.train_texts), {}\n",
    "\n",
    "  # receive global parameter, evaluate model from local's data, return the evaluation result\n",
    "  def evaluate(self, parameters, config):\n",
    "    set_parameters(self.net, parameters)\n",
    "    loss, acc = -1, -1\n",
    "    return float(loss), 1, {\"accuracy\":float(acc)}\n",
    "\n",
    "\n",
    "test = FlowerClient(ETM(len(vocab)), datasets[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(context: Context) -> Client:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    net = ETM(len(vocab)).to(DEVICE)\n",
    "\n",
    "    # Load data (CIFAR-10)\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data partition\n",
    "    # Read the node_config to fetch data partition associated to this node\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    dataset = datasets[partition_id]\n",
    "\n",
    "    # Create a single Flower client representing a single organization\n",
    "    # FlowerClient is a subclass of NumPyClient, so we need to call .to_client()\n",
    "    # to convert it to a subclass of `flwr.client.Client`\n",
    "    return FlowerClient(net, dataset, partition_id).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85551854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveModelStrategy(fl.server.strategy.FedAvg):\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: list[tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]],\n",
    "        failures: list[Union[tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> tuple[Optional[Parameters], dict[str, Scalar]]:\n",
    "\n",
    "        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
    "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(\n",
    "            server_round, results, failures\n",
    "        )\n",
    "\n",
    "        if aggregated_parameters is not None:\n",
    "            # Convert `Parameters` to `list[np.ndarray]`\n",
    "            aggregated_ndarrays: list[np.ndarray] = fl.common.parameters_to_ndarrays(\n",
    "                aggregated_parameters\n",
    "            )\n",
    "\n",
    "            # Save aggregated_ndarrays to disk\n",
    "            if server_round % 10 == 0:\n",
    "                print(f\"Saving round {server_round} aggregated_ndarrays...\")\n",
    "                np.savez(f\"model_parameters/model_round_{server_round}.npz\", *aggregated_ndarrays)\n",
    "\n",
    "        return aggregated_parameters, aggregated_metrics\n",
    "\n",
    "\n",
    "# Create strategy and pass into ServerApp\n",
    "def server_fn(context):\n",
    "    strategy = SaveModelStrategy(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=0.5,\n",
    "        min_fit_clients=NUM_CLIENTS,\n",
    "        min_available_clients=NUM_CLIENTS,\n",
    "    )\n",
    "    config = ServerConfig(num_rounds=NUM_ROUNDS)\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd19cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_server_model(net):\n",
    "    list_of_files = [fname for fname in glob.glob(\"model_parameters/model_round_*\")]\n",
    "    latest_round_file = max(list_of_files, key=os.path.getctime)\n",
    "    print(\"Loading pre-trained model from: \", latest_round_file)\n",
    "    \n",
    "    # Load NumPy arrays from .npz file\n",
    "    with np.load(latest_round_file) as data:\n",
    "        arrays = [data[f'arr_{i}'] for i in range(len(data.files))]\n",
    "    \n",
    "    # Convert to PyTorch state_dict\n",
    "    state_dict = {k: torch.from_numpy(v) for k, v in zip(net.state_dict().keys(), arrays)}\n",
    "    net.load_state_dict(state_dict)\n",
    "    \n",
    "    # Convert to Flower Parameters\n",
    "    state_dict_ndarrays = [v.cpu().numpy() for v in net.state_dict().values()]\n",
    "    parameters = fl.common.ndarrays_to_parameters(state_dict_ndarrays)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a830fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if DEVICE == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
    "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
    "    # and how to set up the `backend_config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fadb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mDEBUG 2025-07-14 18:13:31,990\u001b[0m:     Asyncio event loop already running.\n",
      "\u001b[94mDEBUG 2025-07-14 18:13:31,991\u001b[0m:     Logger propagate set to False\n",
      "\u001b[94mDEBUG 2025-07-14 18:13:31,991\u001b[0m:     Pre-registering run with id 16802060710903922778\n",
      "\u001b[94mDEBUG 2025-07-14 18:13:31,992\u001b[0m:     Using InMemoryState\n",
      "\u001b[94mDEBUG 2025-07-14 18:13:31,992\u001b[0m:     Using InMemoryState\n",
      "\u001b[92mINFO 2025-07-14 18:13:31,995\u001b[0m:      Starting Flower ServerApp, config: num_rounds=30, no round_timeout\n",
      "\u001b[92mINFO 2025-07-14 18:13:32,022\u001b[0m:      \n",
      "\u001b[94mDEBUG 2025-07-14 18:13:32,021\u001b[0m:     Using InMemoryState\n",
      "\u001b[92mINFO 2025-07-14 18:13:32,024\u001b[0m:      [INIT]\n",
      "\u001b[92mINFO 2025-07-14 18:13:32,025\u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[94mDEBUG 2025-07-14 18:13:32,024\u001b[0m:     Registered 2 nodes\n",
      "\u001b[94mDEBUG 2025-07-14 18:13:32,026\u001b[0m:     Supported backends: ['ray']\n",
      "\u001b[94mDEBUG 2025-07-14 18:13:32,027\u001b[0m:     Initialising: RayBackend\n",
      "\u001b[94mDEBUG 2025-07-14 18:13:32,027\u001b[0m:     Backend config: {'client_resources': {'num_cpus': 1, 'num_gpus': 1.0}, 'init_args': {}, 'actor': {'tensorflow': 0}}\n",
      "2025-07-14 18:13:34,879\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[94mDEBUG 2025-07-14 18:13:36,452\u001b[0m:     Constructed ActorPool with: 1 actors\n",
      "\u001b[94mDEBUG 2025-07-14 18:13:36,453\u001b[0m:     Using InMemoryState\n",
      "\u001b[92mINFO 2025-07-14 18:13:51,666\u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO 2025-07-14 18:13:51,667\u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO 2025-07-14 18:13:51,668\u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO 2025-07-14 18:13:51,668\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:13:51,669\u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO 2025-07-14 18:13:51,669\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 1941.7176513671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:13:55,504\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 1894.876220703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING 2025-07-14 18:13:55,556\u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO 2025-07-14 18:13:55,570\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO 2025-07-14 18:13:57,169\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[93mWARNING 2025-07-14 18:13:57,170\u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO 2025-07-14 18:13:57,171\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:13:57,171\u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO 2025-07-14 18:13:57,172\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 1607.691162109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:13:59,423\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 1575.80712890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:13:59,507\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO 2025-07-14 18:14:01,151\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:01,153\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:14:01,153\u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO 2025-07-14 18:14:01,154\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 1390.7388916015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:03,498\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:03,566\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 1354.6754150390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:05,913\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:05,913\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:14:05,914\u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO 2025-07-14 18:14:05,914\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 1227.1517333984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:08,497\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 1197.91015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:08,643\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO 2025-07-14 18:14:11,336\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:11,337\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:14:11,337\u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO 2025-07-14 18:14:11,338\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 1113.5338134765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:14,163\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:14,226\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 1088.9791259765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:15,989\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:15,990\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:14:15,990\u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO 2025-07-14 18:14:15,991\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 1032.0389404296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:18,193\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:18,258\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 1008.400634765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:19,844\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:19,845\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:14:19,846\u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO 2025-07-14 18:14:19,847\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 973.5540161132812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:22,142\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 950.6398315429688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:22,232\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO 2025-07-14 18:14:23,833\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:23,834\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:14:23,835\u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO 2025-07-14 18:14:23,835\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 928.7109985351562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:26,503\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:26,571\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 908.929443359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:28,149\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:28,150\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:14:28,151\u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO 2025-07-14 18:14:28,152\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 896.1220703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:30,375\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:30,441\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 877.8868408203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:32,805\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:32,806\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:14:32,806\u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO 2025-07-14 18:14:32,807\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 872.2798461914062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:36,921\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:37,060\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 854.0929565429688\n",
      "Saving round 10 aggregated_ndarrays...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:39,621\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:39,623\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:14:39,623\u001b[0m:      [ROUND 11]\n",
      "\u001b[92mINFO 2025-07-14 18:14:39,624\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 854.0578002929688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:42,448\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:42,521\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 836.7319946289062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:44,662\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:44,663\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:14:44,664\u001b[0m:      [ROUND 12]\n",
      "\u001b[92mINFO 2025-07-14 18:14:44,664\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 839.989990234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:47,447\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:47,517\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 822.9850463867188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:49,188\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:49,191\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:14:49,193\u001b[0m:      [ROUND 13]\n",
      "\u001b[92mINFO 2025-07-14 18:14:49,196\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 829.7274780273438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:51,638\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 812.7026977539062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:51,726\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO 2025-07-14 18:14:53,486\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:53,490\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:14:53,494\u001b[0m:      [ROUND 14]\n",
      "\u001b[92mINFO 2025-07-14 18:14:53,495\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 820.6788940429688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:56,051\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 804.0509033203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:14:56,141\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO 2025-07-14 18:14:57,810\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:14:57,813\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:14:57,816\u001b[0m:      [ROUND 15]\n",
      "\u001b[92mINFO 2025-07-14 18:14:57,820\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 813.77734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:00,075\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:00,148\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 797.7197265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:02,157\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:02,158\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:15:02,159\u001b[0m:      [ROUND 16]\n",
      "\u001b[92mINFO 2025-07-14 18:15:02,160\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 808.0672607421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:05,360\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:05,444\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 791.8588256835938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:07,228\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:07,230\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:15:07,232\u001b[0m:      [ROUND 17]\n",
      "\u001b[92mINFO 2025-07-14 18:15:07,234\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 803.269775390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:09,410\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:09,471\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 787.1657104492188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:11,186\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:11,188\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:15:11,190\u001b[0m:      [ROUND 18]\n",
      "\u001b[92mINFO 2025-07-14 18:15:11,191\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 799.2686157226562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:13,328\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:13,413\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 782.9991455078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:15,116\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:15,118\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:15:15,121\u001b[0m:      [ROUND 19]\n",
      "\u001b[92mINFO 2025-07-14 18:15:15,125\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 795.6741943359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:17,433\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 779.8207397460938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:17,521\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO 2025-07-14 18:15:19,255\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:19,256\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:15:19,257\u001b[0m:      [ROUND 20]\n",
      "\u001b[92mINFO 2025-07-14 18:15:19,259\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 792.4217529296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:21,427\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:21,527\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 776.630615234375\n",
      "Saving round 20 aggregated_ndarrays...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:23,882\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:23,883\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:15:23,884\u001b[0m:      [ROUND 21]\n",
      "\u001b[92mINFO 2025-07-14 18:15:23,885\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 789.7561645507812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:26,916\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:26,985\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 773.943603515625\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:28,754\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:28,758\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:15:28,761\u001b[0m:      [ROUND 22]\n",
      "\u001b[92mINFO 2025-07-14 18:15:28,764\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 787.2626953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:31,136\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:31,216\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 771.6884155273438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:33,007\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:33,009\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:15:33,011\u001b[0m:      [ROUND 23]\n",
      "\u001b[92mINFO 2025-07-14 18:15:33,013\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 785.361083984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:35,386\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:35,460\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 769.3698120117188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:37,392\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:37,393\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:15:37,395\u001b[0m:      [ROUND 24]\n",
      "\u001b[92mINFO 2025-07-14 18:15:37,397\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 783.0977783203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:39,570\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:39,639\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 767.515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:41,312\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:41,314\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:15:41,318\u001b[0m:      [ROUND 25]\n",
      "\u001b[92mINFO 2025-07-14 18:15:41,321\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 781.4594116210938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:43,858\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 765.8432006835938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:43,986\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO 2025-07-14 18:15:45,927\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:45,929\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:15:45,931\u001b[0m:      [ROUND 26]\n",
      "\u001b[92mINFO 2025-07-14 18:15:45,932\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 780.1004028320312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:48,333\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 764.081298828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:48,407\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO 2025-07-14 18:15:50,256\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:50,258\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:15:50,260\u001b[0m:      [ROUND 27]\n",
      "\u001b[92mINFO 2025-07-14 18:15:50,262\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 778.6409912109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:52,634\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 762.9615478515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:52,712\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO 2025-07-14 18:15:54,857\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:54,858\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:15:54,859\u001b[0m:      [ROUND 28]\n",
      "\u001b[92mINFO 2025-07-14 18:15:54,860\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 777.0335693359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:15:58,379\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:15:58,509\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 761.2867431640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:16:00,435\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:16:00,436\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:16:00,437\u001b[0m:      [ROUND 29]\n",
      "\u001b[92mINFO 2025-07-14 18:16:00,438\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 775.8414306640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:16:03,839\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 760.3041381835938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:16:03,955\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO 2025-07-14 18:16:06,243\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:16:06,244\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:16:06,245\u001b[0m:      [ROUND 30]\n",
      "\u001b[92mINFO 2025-07-14 18:16:06,245\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client0\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 774.8886108398438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:16:09,586\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Client's model: ETM_Client1\n",
      "\u001b[36m(ClientAppActor pid=13816)\u001b[0m Epoch: 000 | Loss: 759.038818359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:16:09,721\u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 30 aggregated_ndarrays...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO 2025-07-14 18:16:11,746\u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,763\u001b[0m:      \n",
      "\u001b[92mINFO 2025-07-14 18:16:11,763\u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,764\u001b[0m:      Run finished 30 round(s) in 140.08s\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,765\u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,766\u001b[0m:      \t\tround 1: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,766\u001b[0m:      \t\tround 2: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,767\u001b[0m:      \t\tround 3: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,767\u001b[0m:      \t\tround 4: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,768\u001b[0m:      \t\tround 5: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,768\u001b[0m:      \t\tround 6: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,768\u001b[0m:      \t\tround 7: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,769\u001b[0m:      \t\tround 8: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,769\u001b[0m:      \t\tround 9: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,770\u001b[0m:      \t\tround 10: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,770\u001b[0m:      \t\tround 11: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,771\u001b[0m:      \t\tround 12: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,771\u001b[0m:      \t\tround 13: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,772\u001b[0m:      \t\tround 14: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,772\u001b[0m:      \t\tround 15: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,773\u001b[0m:      \t\tround 16: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,773\u001b[0m:      \t\tround 17: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,774\u001b[0m:      \t\tround 18: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,774\u001b[0m:      \t\tround 19: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,774\u001b[0m:      \t\tround 20: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,776\u001b[0m:      \t\tround 21: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,777\u001b[0m:      \t\tround 22: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,777\u001b[0m:      \t\tround 23: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,778\u001b[0m:      \t\tround 24: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,779\u001b[0m:      \t\tround 25: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,779\u001b[0m:      \t\tround 26: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,780\u001b[0m:      \t\tround 27: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,780\u001b[0m:      \t\tround 28: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,781\u001b[0m:      \t\tround 29: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,781\u001b[0m:      \t\tround 30: -1.0\n",
      "\u001b[92mINFO 2025-07-14 18:16:11,782\u001b[0m:      \n",
      "\u001b[94mDEBUG 2025-07-14 18:16:11,785\u001b[0m:     ServerApp finished running.\n",
      "\u001b[94mDEBUG 2025-07-14 18:16:11,787\u001b[0m:     ServerApp finished running.\n",
      "\u001b[94mDEBUG 2025-07-14 18:16:11,787\u001b[0m:     Triggered stop event for Simulation Engine.\n",
      "\u001b[94mDEBUG 2025-07-14 18:16:12,696\u001b[0m:     Terminated 1 actors\n",
      "\u001b[94mDEBUG 2025-07-14 18:16:13,740\u001b[0m:     Terminated RayBackend\n",
      "\u001b[94mDEBUG 2025-07-14 18:16:13,741\u001b[0m:     Stopping Simulation Engine now.\n"
     ]
    }
   ],
   "source": [
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    "    verbose_logging=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912afd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model from:  model_parameters\\model_round_20.npz\n",
      "Topic 0: mac later keys started pittsburgh date health dod crime previous development engineering involved follow media\n",
      "Topic 1: state technology clipper remember important comes network looks study usually ideas york religious second sounds\n",
      "Topic 2: data end interested went california reference genocide laboratory town visual rangers prevent turbo florida closer\n",
      "Topic 3: second let away ask similar series note error press ground player food safety generally contains\n",
      "Topic 4: cost machine future problems section speak higher device launch response escrow modern army received performance\n",
      "Topic 5: lot research phone trying paul april states force bus religion atheists common condition reserve easily\n",
      "Topic 6: version getting value bike asked cards rules scott died audio completely hey truth listen shown\n",
      "Topic 7: think way space law access live known ones care policy chris total education issue ken\n",
      "Topic 8: car image run problems history issue action baseball bbs return toronto view tom format red\n",
      "Topic 9: question look came actually check write love legal san written possible machines truth quality friends\n",
      "Topic 10: people said got encryption left stuff level newsreader making numbers young early keith clear greek\n",
      "Topic 11: max number jesus scsi output talking country statement coming purpose office richard effect north particular\n",
      "Topic 12: drive post hockey voice local citizens analysis mass understanding easier attempt risk marc club spent\n",
      "Topic 13: support gun non michael small fax institute school area working speed deal faq jewish apple\n",
      "Topic 14: know time available file seen questions runs secret told political dog technical seek cache pat\n",
      "Topic 15: god windows read bible human war current code distribution example division open offer needed knows\n",
      "Topic 16: information things news israel christian house mind security saw strong land andrew willing method server\n",
      "Topic 17: nntp distribution able unix armenian death wanted smith newsgroup happen ways model orbit die internal\n",
      "Topic 18: old thought running american drivers company fact cases report sites record cable comments memory increase\n",
      "Topic 19: help going year true president anybody user consider size brian process accept military gone base\n",
      "Topic 20: university sure thing change wrong correct programs washington built peter posts drugs library author comment\n",
      "Topic 21: years better program software real wrote price government feel address works department christians single instead\n",
      "Topic 22: want thanks systems need internet exist church nasa special net texas society leave disclaimer night\n",
      "Topic 23: day looking heard opinions bad college difference cause times server rate theory told low appreciated\n",
      "Topic 24: pretty directory stupid solution son driving claims argic protection doctor continue physics double beat worked\n",
      "Topic 25: new list team yes fact ago air tried cars took illinois site gave approach event\n",
      "Topic 26: kind private steve screen add thomas tax ram deleted roger fred bmw sexual bytes pre\n",
      "Topic 27: posting good reply problem long high apr center jews sun box sorry city called needs\n",
      "Topic 28: card national copy users dead fbi ray thinking practice tools braves random eye coverage villages\n",
      "Topic 29: new line standard following money simple earth digital month including supports race biblical references int\n",
      "Topic 30: article key message word saying men league rest radio wants save scientific protect necessarily party\n",
      "Topic 31: hard government possible text drives short week interesting knowledge personal figure court tim controller average\n",
      "Topic 32: power keywords person believe hand days agree answer happened guy act sound armenia boston result\n",
      "Topic 33: set big win given rights simply hope advance especially plus road insurance firearms hardware room\n",
      "Topic 34: case window dos robert understand turn easy lost major uunet wonder stand late morality america\n",
      "Topic 35: work mark believe canada guess taken mouse obviously values suggest answers virginia family caused paid\n",
      "Topic 36: organization point makes display stop members design details muslim excellent turned mike calling provides kids\n",
      "Topic 37: host send free idea turkish sale says color certain self groups mode manager tape maybe\n",
      "Topic 38: life info players claim armenians include light contact form weapons allow months guns getting field\n",
      "Topic 39: writes right probably man home email jim corporation objective individual originator reasonable winning cpu generation\n",
      "Topic 40: mail usa public control means order source driver ftp motif services season package turkey hear\n",
      "Topic 41: use great game christ times pin stephen medicine pressure keeping colors happening handling congress bob\n",
      "Topic 42: like course mean games game buy couple james chicago application tin anti according low south\n",
      "Topic 43: subject tell provide points faith talk function nature letter apply responsible auto luck encrypted processing\n",
      "Topic 44: david university science try chip start posted called books uses pub anonymous kill unit business\n",
      "Topic 45: lines bit based general large police sense killed require carry frank directly independent bought longer\n",
      "Topic 46: little come group reason place maybe run evidence period argument computing monitor build outside goal\n",
      "Topic 47: far dept israeli words printer related title reality jon lee soviet beliefs entry killing round\n",
      "Topic 48: world john best need play today book type video original pay exactly discussion international western\n",
      "Topic 49: files different graphics matter body example specific results plan lots realize forget ride mission economic\n"
     ]
    }
   ],
   "source": [
    "from utils._utils import get_top_words\n",
    "net = ETM(len(vocab))\n",
    "test = get_latest_server_model(net)\n",
    "beta = net.get_beta().detach().cpu().numpy()\n",
    "topwords = get_top_words(beta, vocab, 15, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6075b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BasicTrainer(net, datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05de09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETM(\n",
       "  (encoder1): Sequential(\n",
       "    (0): Linear(in_features=5000, out_features=800, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (fc21): Linear(in_features=800, out_features=50, bias=True)\n",
       "  (fc22): Linear(in_features=800, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac98a3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing texts: 100%|██████████| 2/2 [00:00<00:00, 1971.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5000)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "[ 7 15]\n",
      "think way space law access live known ones care policy chris total education issue ken\n",
      "god windows read bible human war current code distribution example division open offer needed knows\n"
     ]
    }
   ],
   "source": [
    "########################### test new documents ####################################\n",
    "from data.preprocess import Preprocess\n",
    "\n",
    "preprocess = Preprocess()\n",
    "\n",
    "new_docs = [\n",
    "    \"This is a new document about space, including words like space, satellite, launch, orbit.\",\n",
    "    \"This is a new document about Microsoft Windows, including words like windows, files, dos.\"\n",
    "]\n",
    "\n",
    "parsed_new_docs, new_bow = preprocess.parse(new_docs, vocab)\n",
    "print(new_bow.shape)\n",
    "\n",
    "print(new_bow.toarray())\n",
    "input = torch.as_tensor(new_bow.toarray(), device=\"cuda\").float()\n",
    "print(input)\n",
    "new_theta = trainer.test(input)\n",
    "\n",
    "print(new_theta.argmax(1))\n",
    "for x in new_theta.argmax(1):\n",
    "    print(topwords[x])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
