{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5237b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data.basic_dataset import BasicDataset\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from utils import _utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb94c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTrainer:\n",
    "    def __init__(self, \n",
    "                 model : nn.Module,\n",
    "                 dataset : BasicDataset,\n",
    "                 num_top_words = 15,\n",
    "                 epochs = 200,\n",
    "                 learning_rate = 0.002,\n",
    "                 batch_size = 200,\n",
    "                 verbose = False,\n",
    "                 device = \"cuda\"):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.num_top_words = num_top_words\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.log_interval = 1\n",
    "        self.data_size = len(self.dataset.train_data)\n",
    "        self.device = device\n",
    "\n",
    "    def make_optimizer(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr = self.learning_rate)\n",
    "    \n",
    "    def train(self, model_name = None, global_round = None):\n",
    "        optimizer = self.make_optimizer()\n",
    "        if model_name is not None:\n",
    "            print(f\"Client's model: {model_name} \\t | Global round: {global_round}\")\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0.0\n",
    "            for batch_data in self.dataset.train_dataloader:\n",
    "                batch_data = batch_data.to(self.device)\n",
    "                output = self.model(batch_data)\n",
    "\n",
    "                batch_loss = output['loss']\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += batch_loss * len(batch_data)\n",
    "\n",
    "            if (epoch % self.log_interval == 0):    \n",
    "                print(f\"Epoch: {epoch:03d} | Loss: {total_loss / self.data_size}\")\n",
    "\n",
    "        top_words = self.get_top_words()\n",
    "        train_theta = self.test(self.dataset.train_data)\n",
    "\n",
    "        return top_words, train_theta\n",
    "\n",
    "    def test(self, bow):\n",
    "        data_size = bow.shape[0]\n",
    "        theta = list()\n",
    "        all_idx = torch.split(torch.arange(data_size), self.batch_size)\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            for idx in all_idx:\n",
    "                batch_input = bow[idx]\n",
    "                batch_input = batch_input.to(self.device)\n",
    "                # print(batch_input.device)\n",
    "                batch_theta = self.model.get_theta(batch_input)\n",
    "                theta.extend(batch_theta.cpu().tolist())\n",
    "\n",
    "        theta = np.asarray(theta)\n",
    "        return theta\n",
    "\n",
    "    def get_beta(self):\n",
    "        beta = self.model.get_beta().detach().cpu().numpy()\n",
    "        return beta\n",
    "\n",
    "    def get_top_words(self, num_top_words=None):\n",
    "        if num_top_words is None:\n",
    "            num_top_words = self.num_top_words\n",
    "        beta = self.get_beta()\n",
    "        top_words = _utils.get_top_words(beta, self.dataset.vocab, num_top_words, self.verbose)\n",
    "        return top_words\n",
    "\n",
    "    def export_theta(self):\n",
    "        train_theta = self.test(self.dataset.train_data)\n",
    "        test_theta = self.test(self.dataset.test_data)\n",
    "        return train_theta, test_theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5693725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing texts: 100%|██████████| 2/2 [00:00<00:00, 329.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5000)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[26 27]\n"
     ]
    }
   ],
   "source": [
    "########################### test new documents ####################################\n",
    "from data.preprocess import Preprocess\n",
    "\n",
    "preprocess = Preprocess()\n",
    "\n",
    "new_docs = [\n",
    "    \"This is a new document about space, including words like space, satellite, launch, orbit.\",\n",
    "    \"This is a new document about Microsoft Windows, including words like windows, files, dos.\"\n",
    "]\n",
    "\n",
    "parsed_new_docs, new_bow = preprocess.parse(new_docs, vocab=test_basic_dataset.vocab)\n",
    "print(new_bow.shape)\n",
    "\n",
    "print(new_bow.toarray())\n",
    "input = torch.as_tensor(new_bow.toarray(), device=\"cuda\").float()\n",
    "new_theta = test_basic_trainer.test(input)\n",
    "\n",
    "print(new_theta.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdab07d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words, train_theta = rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f680114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation.topic_coherence as tc\n",
    "import evaluation.topic_diversity as td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25c958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_score = tc._coherence(test_basic_dataset.train_texts, test_basic_dataset.vocab, top_words)\n",
    "diversity_score = td._diversity(top_words)\n",
    "\n",
    "print(f\"Topic coherence: {coherence_score}\")\n",
    "print(f\"Topic diversity: {diversity_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629fd223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great space nntp american whether full video likely kill existence directory tom die language engineering\n",
      "like post dos washington almost start talking together else friends shot title total chris tools\n"
     ]
    }
   ],
   "source": [
    "for x in new_theta.argmax(1):\n",
    "    print(top_words[x])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
